{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training notebook/script 2\n",
        "#### Starting with some imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image\n",
        "import cv2 as cv\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as T\n",
        "from torchvision.utils import make_grid\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm.notebook import tqdm\n",
        "%matplotlib inline"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Defining directories and instantiating the main dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "root_dir=\"./training/rgb/\"\n",
        "csv_file=os.path.join(root_dir, \"training_xy.csv\")\n",
        "main_df=pd.read_csv(csv_file, header=None).iloc[:32560, :]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Dataset\n",
        "#### Defining the blueprint of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class FreihandDataset(Dataset):\n",
        "    def __init__(self, root_dir, csv_file, transforms=None):\n",
        "        self.main_df=pd.read_csv(csv_file, header=None).iloc[:32560, :]\n",
        "        self.root_dir=root_dir\n",
        "        self.transforms=transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.main_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_dir=os.path.join(self.root_dir, self.main_df.iloc[idx, 0])\n",
        "        image=Image.open(img_dir)\n",
        "        if self.transforms:\n",
        "            image=self.transforms(image)\n",
        "        keypoints=torch.from_numpy(self.main_df.iloc[idx, 1:].astype(\"float\").to_numpy())\n",
        "        return image, keypoints"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Initializing an instance of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset=FreihandDataset(root_dir, csv_file, transforms=T.ToTensor())\n",
        "len(dataset)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Splitting the dataset\n",
        "#### Defining the training and validation set sizes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "val_set_len=int(0.2*len(dataset))\n",
        "train_set_len=len(dataset)-val_set_len\n",
        "train_set_len, val_set_len\n",
        "train_set, val_set=random_split(dataset, [train_set_len, val_set_len])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating Dataloader workers\n",
        "#### Using torch.utils.data.DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "batch_size=32\n",
        "train_dl=DataLoader(train_set, batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
        "val_dl=DataLoader(val_set, batch_size, num_workers=0, pin_memory=True)\n",
        "\n",
        "for batch in train_dl:\n",
        "    print(batch)\n",
        "    break"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining utility functions\n",
        "#### Function to show the image with keypoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def show_keypoints(img_name):\n",
        "    plt.clf()\n",
        "    img_dir=os.path.join(root_dir, img_name)\n",
        "    image=Image.open(img_dir)\n",
        "    keypoints=main_df[main_df[0]==img_name].iloc[0, 1:].astype(\"float\").to_numpy().reshape(-1,2)\n",
        "    plt.imshow(image)\n",
        "    plt.scatter(keypoints[:, 0], keypoints[:, 1], s=20, marker='.', c='m')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "show_keypoints(main_df.iloc[321, 0])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Function to get the default device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_default_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    return torch.device('cpu')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "device=get_default_device()\n",
        "device"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Function to move data to the GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def to_device(data, device):\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Device Dataloaders\n",
        "#### The blueprint defined below is used to create instances of Dataloaders on a particular device (here, the GPU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class DeviceDataLoader():\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dl)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Instantiating device Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_dl=DeviceDataLoader(train_dl, device)\n",
        "val_dl=DeviceDataLoader(val_dl, device)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Model\n",
        "#### Importing the required architecture (resnet34) and creating model instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import models as archs\n",
        "model=archs.Net2()\n",
        "model"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Uncomment the below cell to load a custom pretrained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# pth_filename=???\n",
        "# model.load_state_dict(torch.load(pth_filename))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Moving the model to the default device (here, GPU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model.to(device)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper functions to train and evaluate the model\n",
        "#### Function to run validation passes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def validate(model, val_dl):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        validation_output=[model.validation_step(batch) for batch in val_dl]\n",
        "        return model.validation_per_epoch(validation_output)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Function to retrieve current learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Function to train the model for a specified number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def train(epochs, max_lr, model, train_dl, val_dl, weight_decay=0, opt_func=torch.optim.SGD, print_loss=True):\n",
        "    torch.cuda.empty_cache()\n",
        "    history=[]\n",
        "    optimizer=opt_func(model.parameters(), lr=max_lr, weight_decay=weight_decay)\n",
        "    sched=torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_dl))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "\n",
        "        train_losses=[]\n",
        "        lrs=[]\n",
        "        for batch in tqdm(train_dl):\n",
        "            loss=model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            lrs.append(get_lr(optimizer))\n",
        "            sched.step()\n",
        "\n",
        "        res=validate(model, val_dl)\n",
        "        res[\"train_loss\"]=torch.stack(train_losses).mean().item()\n",
        "        res[\"lrs\"]=lrs\n",
        "\n",
        "        if print_loss:\n",
        "            print(f\"Epoch[{epoch}] -> Training Loss: {res['train_loss']}, Validation Loss: {res['val_loss']}\")\n",
        "\n",
        "        history.append(res)\n",
        "    return history"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training the model\n",
        "#### Start off by testing how long a single epoch takes to train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "history=train(1, 0.001, model, train_dl, val_dl)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Add more cells and train for more epochs with varying learning rates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# history+=train(???, ???, model, train_dl, val_dl)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### After training, save the model to disk, to prevent retraining from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "torch.save(model.state_dict(), \"last.pth\")\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}